{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configuration\n",
    "import os\n",
    "import pandas \n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "from scipy.spatial import KDTree\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn import model_selection, linear_model\n",
    "import scipy.io as io\n",
    "import fastparquet\n",
    "import snappy\n",
    "import subprocess\n",
    "import random\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import cupy as cp\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "# import torch\n",
    "start = time.time()\n",
    "mempool = cp.get_default_memory_pool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Gene*Samples matrix of the cerebellum\n",
    "3466x15633 to 337x15624"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default directory\n",
    "atlas = '/n02dat01/users/ypwang/Gradient/GeneticGradient/Data/Cerebellum-MNIfnirt-maxprob-thr25.nii'\n",
    "aba_dir = '/n01dat01/ypwang/Software/abagen/OriginalData_copy/'\n",
    "data_dir = '/n02dat01/users/ypwang/Gradient/GeneticGradient/Data'\n",
    "fig_dir = '/n02dat01/users/ypwang/Gradient/GeneticGradient/Fig/PLSR_2022.09.12/'                                      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_*_coding:utf-8_*_\n",
    "import sys\n",
    "sys.path.append('/n02dat01/users/ypwang/Gradient/GeneticGradient/Scripts/self_corrected_library/')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport abagen_cere.abagen.allen_cere\n",
    "from abagen_nosuit.abagen import allen\n",
    "# from abagen_cere.abagen import allen_cere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # allen_cere.get_samples_in_mask_annot\n",
    "# # allen.get_samples_in_mask_annot\n",
    "\n",
    "expression_all, report_all = allen.get_samples_in_mask_annot(data_dir=aba_dir,   \n",
    "                                                             corrected_mni=True, \n",
    "                                                             return_report=True,\n",
    "                                                             Allsample_nodrop='noB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report = pandas.DataFrame(report_all[report_all.slab_type=='CB'], copy=True)\n",
    "# report = pandas.DataFrame(report[-report.structure_name.str.contains('nucleus')], copy=True) # From 368*18 to 337*18\n",
    "# expression = expression_all[expression_all.index.isin(report.index)]\n",
    "# report.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read in the corrected cordinates\n",
    "# coord_pth = '/n02dat01/users/ypwang/Gradient/AHBA_SampleCorrrected/Donor/'\n",
    "# sasheets = sorted(glob(os.path.join(coord_pth,'*/*_mni_coordinates.csv')))\n",
    "# ref = []\n",
    "# for sheet in sasheets:\n",
    "#     did = sheet.split('/')[-2]\n",
    "#     sa = pandas.read_csv(sheet, header=None)\n",
    "#     sa.columns = ['suit_x', 'suit_y', 'suit_z']\n",
    "#     sa.index = report[report.donor==did].index\n",
    "#     ref.append(sa)\n",
    "# SA = pandas.concat(ref)\n",
    "# report = pandas.merge(report, SA, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas.DataFrame(expression).to_csv(os.path.join(data_dir,'expression_cere_337.csv'))\n",
    "# pandas.DataFrame(report).to_csv(os.path.join(data_dir,'report_cere_337.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 FG of each cerebellar sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def disbtw(surf, aa):\n",
    "#     surf= np.array(surf)\n",
    "#     aa = np.expand_dims(aa,axis=0)\n",
    "#     dis = np.sqrt(((surf-aa)**2).sum(axis=1))\n",
    "#     return dis\n",
    "\n",
    "# def Grid2world(GridList, affine):\n",
    "#     \"\"\"\n",
    "#     trans the grid coords into the corresponding MNI coords in MNI space\n",
    "#     GridList shape: N*3, affine shape 4*4\n",
    "#     \"\"\"\n",
    "#     GridList = np.array(GridList)\n",
    "#     length = len(GridList)\n",
    "#     affine = np.array(affine)\n",
    "#     Grid_coord = np.concatenate([GridList, np.ones([length, 1])], axis=1)\n",
    "#     MNI_coord = Grid_coord.dot(affine.T)      \n",
    "#     MNI_coord = MNI_coord.round(2)\n",
    "#     return MNI_coord[:, :3]\n",
    "# expression = pandas.read_csv(os.path.join(data_dir,'expression_cere_337.csv'), index_col=0)\n",
    "# report = pandas.read_csv(os.path.join(data_dir,'report_cere_337.csv'), index_col=0)\n",
    "# loclist = report[['suit_x','suit_y','suit_z']].values.astype('float')\n",
    "\n",
    "# Rad_dir = '/n02dat01/users/ypwang/Gradient/GeneticGradient/Data/BestRad/'\n",
    "# xpsheets_name = '/n02dat01/users/ypwang/Gradient/GeneticGradient/Data/FG_noBrainSmash/result_cere2extra_gradient*__z_17853_nifti.nii'\n",
    "# xpsheets = sorted(glob(xpsheets_name))\n",
    "# y_gradient = {}\n",
    "# for sheet in xpsheets: \n",
    "#     fid = sheet.split('/')[-1].split('_')[-5] # get functional gradient id\n",
    "#     print(fid)\n",
    "#     gradient_file = nib.load(sheet)\n",
    "#     gradient = gradient_file.get_data()\n",
    "#     affine = gradient_file.affine\n",
    "#     grid_list = np.nonzero(gradient)   \n",
    "#     grad_value = gradient[grid_list] \n",
    "#     rrlist = []\n",
    "#     MNI_loc = Grid2world(np.array(grid_list).T, affine)\n",
    "#     for loc in loclist:\n",
    "#         dis = disbtw(MNI_loc, loc)\n",
    "#         tmp = grad_value[dis<4].mean()\n",
    "#         rrlist.append(tmp)\n",
    "#     # print(np.array(rrlist))\n",
    "#     filename = 'Rad4mm_' + str(fid) + '_sample337_cere2extra.csv'\n",
    "#     pd.DataFrame(rrlist).to_csv(os.path.join(Rad_dir,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_gradient = {}\n",
    "# xpsheets = sorted(glob('/n02dat01/users/ypwang/Gradient/GeneticGradient/Data/BestRad/Rad4mm_*_sample337_cere2extra.csv'))\n",
    "# for sheet in xpsheets:\n",
    "#     fid = sheet.split('/')[-1].split('_')[1] \n",
    "#     y_gradient[fid] = pandas.DataFrame(pandas.read_csv(sheet, index_col=0))\n",
    "#     y_gradient[fid].index = report.index\n",
    "#     report[fid] = np.NaN\n",
    "#     for x in report.index:\n",
    "#         report.loc[x,fid] = y_gradient[fid].loc[x].values\n",
    "#     y_gradient[fid] = y_gradient[fid].values.tolist()\n",
    "# pandas.DataFrame(expression).to_csv(os.path.join(data_dir,'expression_suit4mm_337_cere2extra.csv'))\n",
    "# pandas.DataFrame(report).to_csv(os.path.join(data_dir,'report_suit4mm_337_cere2extra.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expression = pandas.read_csv(os.path.join(data_dir,'expression_suit4mm_337_cere2extra.csv'), index_col=0)\n",
    "# report = pandas.read_csv(os.path.join(data_dir,'report_suit4mm_337_cere2extra.csv'), index_col=0)\n",
    "# report.index = expression.index\n",
    "# report_cur = report[~np.isnan(report['gradient1'])]\n",
    "# expression_cur = expression[~np.isnan(report['gradient1'])]\n",
    "# report = report_cur.iloc[np.where(report_cur['gradient1']!=0)]\n",
    "# expression = expression_cur.iloc[np.where(report_cur['gradient1']!=0)]\n",
    "# pandas.DataFrame(expression).to_csv(os.path.join(data_dir,'expression_4mm_317_cere2extra.csv'))\n",
    "# pandas.DataFrame(report).to_csv(os.path.join(data_dir,'report_4mm_317_cere2extra.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 PLSR: Gene to predict FG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "git_dir = '/n02dat01/users/ypwang/Gradient/GeneticGradient/Scripts/'\n",
    "import sys\n",
    "sys.path.insert(0,git_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport FunctionLibrary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression = pandas.read_csv(os.path.join(data_dir,'expression_4mm_317_cere2extra.csv'), index_col=0)\n",
    "report = pandas.read_csv(os.path.join(data_dir,'report_4mm_317_cere2extra.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Use 10 cv to confirm the optimal component number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color bar\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "\n",
    "def get_dominant_colors(infile):\n",
    "    image = Image.open(infile)\n",
    "    \n",
    "    # 缩小图片，否则计算机压力太大\n",
    "    small_image = image.resize((80, 80))\n",
    "    result = small_image.convert(\n",
    "        \"P\", palette=Image.ADAPTIVE, colors=10\n",
    "    )  \n",
    "\t\n",
    "\t# 10个主要颜色的图像\n",
    "\n",
    "    # 找到主要的颜色\n",
    "    palette = result.getpalette()\n",
    "    color_counts = sorted(result.getcolors(), reverse=True)\n",
    "    colors = list()\n",
    "\n",
    "    for i in range(10):\n",
    "        palette_index = color_counts[i][1]\n",
    "        dominant_color = palette[palette_index * 3 : palette_index * 3 + 3]\n",
    "        colors.append(tuple(dominant_color))\n",
    "\n",
    "    # print(colors)\n",
    "    return colors\n",
    "\n",
    "def RGB_to_Hex(rgb):\n",
    "    RGB = rgb.split(',')\n",
    "    color = '#'\n",
    "    for i in RGB:\n",
    "        num = int(i)\n",
    "        color += str(hex(num))[-2:].replace('x', '0').upper()\n",
    "    return color\n",
    "\n",
    "\n",
    "image_path = \"/n02dat01/users/ypwang/Gradient/GeneticGradient/Data/FG_noBrainSmash/result_cere2extra_gradient1__z_17853.png\"\n",
    "color_1 = get_dominant_colors(image_path)\n",
    "print(color_1)\n",
    "color_rgb = [str(x).replace('(','').replace(')','')  for x in color_1]\n",
    "Hex_1 = [RGB_to_Hex(x) for x in color_rgb]\n",
    "\n",
    "image_path = \"/n02dat01/users/ypwang/Gradient/GeneticGradient/Fig/Color/红包配色.jpg\"\n",
    "color_2 = get_dominant_colors(image_path)\n",
    "print(color_2)\n",
    "color_rgb = [str(x).replace('(','').replace(')','')  for x in color_2]\n",
    "Hex_2 = [RGB_to_Hex(x) for x in color_rgb]\n",
    "sns.palplot(Hex_1)\n",
    "sns.palplot(Hex_2)\n",
    "\n",
    "from matplotlib import cm\n",
    "jet_10 = cm.get_cmap('jet', 10)(np.arange(10))\n",
    "cm.get_cmap('jet', 10)\n",
    "\n",
    "jet_9 = cm.get_cmap('jet', 9)(np.arange(9))\n",
    "cm.get_cmap('jet', 9)\n",
    "\n",
    "RdBu_9 = cm.get_cmap('RdBu', 9)(np.arange(9))\n",
    "cm.get_cmap('RdBu', 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import scipy.stats as stats\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "start = time.time()\n",
    "def add(x, y):\n",
    "\treturn x+y\n",
    "def merge_add(args):\n",
    "\treturn add(*args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Component_eval_10cv(times):\n",
    "    cv=10\n",
    "    cv_inner=10\n",
    "    y = report['gradient1']\n",
    "    best_comps = []\n",
    "    r = []\n",
    "    preds = pandas.DataFrame(np.zeros((len(y))))\n",
    "    preds.index = expression.index\n",
    "    ncomps=np.arange(1,11)\n",
    "    sel = model_selection.KFold(n_splits=cv, shuffle=True, random_state=(123 * (times+1)))    \n",
    "    sel_inner = model_selection.KFold(n_splits=cv_inner, shuffle=True, random_state=(123 * (times+1)))\n",
    "    for tr_ind, te_ind in sel.split(expression):\n",
    "        mse=[]\n",
    "        expression_cur = expression.iloc[tr_ind,:]\n",
    "        for tr_i, te_i in sel_inner.split(expression_cur):\n",
    "            mse.append([])\n",
    "            tr_cols = expression.index[tr_ind][tr_i]\n",
    "            tr_set = pandas.DataFrame(expression.loc[tr_cols,:], copy=True)\n",
    "            tr_y = pandas.DataFrame(report['gradient1']).loc[tr_cols,:]\n",
    "            te_cols = expression.index[tr_ind][te_i]\n",
    "            te_set = pandas.DataFrame(expression.loc[te_cols,:], copy=True)\n",
    "            te_y = pandas.DataFrame(report['gradient1']).loc[te_cols,:]\n",
    "            for nc in ncomps:\n",
    "                clf = PLSRegression(n_components=nc)\n",
    "                pred_y = clf.fit(tr_set,tr_y).predict(te_set).flatten()\n",
    "                mse[-1].append(mean_squared_error(te_y,pred_y))\n",
    "        mse = np.sum(mse,axis=0)\n",
    "        nc = ncomps[np.argmin(mse)]\n",
    "        best_comps.append(nc)\n",
    "        #refit full model\n",
    "        clf = PLSRegression(n_components=nc)\n",
    "        tr_cols = expression.index[tr_ind]\n",
    "        tr_set = pandas.DataFrame(expression.loc[tr_cols,:], copy=True)\n",
    "        tr_y = pandas.DataFrame(report['gradient1']).iloc[tr_ind,:]\n",
    "        te_cols = expression.index[te_ind]\n",
    "        te_set = pandas.DataFrame(expression.loc[te_cols,:], copy=True)\n",
    "        te_y = pandas.DataFrame(report['gradient1']).iloc[te_ind,:]\n",
    "        mod = clf.fit(tr_set,tr_y)\n",
    "        preds.loc[te_cols,:] = mod.predict(te_set)\n",
    "        r.append(stats.pearsonr(mod.predict(te_set).flatten(), te_y)[0])\n",
    "    return best_comps,r,preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv=10\n",
    "# cv_inner=10\n",
    "# y = report['gradient1']\n",
    "# best_comps = []\n",
    "# r = []\n",
    "# preds = pandas.DataFrame(np.zeros((len(y))))\n",
    "# preds.index = expression.index\n",
    "# ncomps=np.arange(1,11)\n",
    "# sel = model_selection.KFold(n_splits=cv, shuffle=True)    \n",
    "# sel_inner = model_selection.KFold(n_splits=cv_inner, shuffle=True)\n",
    "\n",
    "# for tr_ind, te_ind in sel.split(expression):\n",
    "#     mse=[]\n",
    "#     expression_cur = expression.iloc[tr_ind,:]\n",
    "#     for tr_i, te_i in sel_inner.split(expression_cur):\n",
    "#         mse.append([])\n",
    "#         tr_cols = expression.index[tr_ind][tr_i]\n",
    "#         tr_set = pandas.DataFrame(expression.loc[tr_cols,:], copy=True)\n",
    "#         tr_y = pandas.DataFrame(report['gradient1']).loc[tr_cols,:]\n",
    "#         te_cols = expression.index[tr_ind][te_i]\n",
    "#         te_set = pandas.DataFrame(expression.loc[te_cols,:], copy=True)\n",
    "#         te_y = pandas.DataFrame(report['gradient1']).loc[te_cols,:]\n",
    "#         for nc in ncomps:\n",
    "#             clf = PLSRegression(n_components=nc)\n",
    "#             pred_y = clf.fit(tr_set,tr_y).predict(te_set).flatten()\n",
    "#             mse[-1].append(mean_squared_error(te_y,pred_y))\n",
    "#     mse = np.sum(mse,axis=0)\n",
    "#     nc = ncomps[np.argmin(mse)]\n",
    "#     best_comps.append(nc)\n",
    "#     #refit full model\n",
    "#     clf = PLSRegression(n_components=nc)\n",
    "#     tr_cols = expression.index[tr_ind]\n",
    "#     tr_set = pandas.DataFrame(expression.loc[tr_cols,:], copy=True)\n",
    "#     tr_y = pandas.DataFrame(report['gradient1']).iloc[tr_ind,:]\n",
    "#     te_cols = expression.index[te_ind]\n",
    "#     te_set = pandas.DataFrame(expression.loc[te_cols,:], copy=True)\n",
    "#     te_y = pandas.DataFrame(report['gradient1']).iloc[te_ind,:]\n",
    "#     mod = clf.fit(tr_set,tr_y)\n",
    "#     preds.loc[te_cols,:] = mod.predict(te_set)\n",
    "#     r.append(stats.pearsonr(mod.predict(te_set).flatten(), te_y)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cores = multiprocessing.cpu_count()\n",
    "# pool = multiprocessing.Pool(processes=cores)\n",
    "\n",
    "# times = 10\n",
    "# tasks = [[x] for x in range(1,times+1)]\n",
    "# print(tasks)\n",
    "# ans = pool.starmap(Component_eval_10cv,tasks)\n",
    "# np.save(f'{data_dir}/Component_eval_10cv_{times}times', ans) \n",
    "\n",
    "\n",
    "# cores = multiprocessing.cpu_count()\n",
    "# pool = multiprocessing.Pool(processes=cores)\n",
    "\n",
    "# times = 20\n",
    "# tasks = [[x] for x in range(11,times+1)]\n",
    "# print(tasks)\n",
    "# ans = pool.starmap(Component_eval_10cv,tasks)\n",
    "# np.save(f'{data_dir}/Component_eval_10cv_{times}times', ans) \n",
    "# cores = multiprocessing.cpu_count()\n",
    "# pool = multiprocessing.Pool(processes=cores)\n",
    "\n",
    "# times = 30\n",
    "# tasks = [[x] for x in range(21,times+1)]\n",
    "# print(tasks)\n",
    "# ans = pool.starmap(Component_eval_10cv,tasks)\n",
    "# np.save(f'{data_dir}/Component_eval_10cv_{times}times', ans) \n",
    "# cores = multiprocessing.cpu_count()\n",
    "# pool = multiprocessing.Pool(processes=cores)\n",
    "\n",
    "# times = 40\n",
    "# tasks = [[x] for x in range(31,times+1)]\n",
    "# print(tasks)\n",
    "# ans = pool.starmap(Component_eval_10cv,tasks)\n",
    "# np.save(f'{data_dir}/Component_eval_10cv_{times}times', ans) \n",
    "# cores = multiprocessing.cpu_count()\n",
    "# pool = multiprocessing.Pool(processes=cores)\n",
    "\n",
    "# times = 50\n",
    "# tasks = [[x] for x in range(41,times+1)]\n",
    "# print(tasks)\n",
    "# ans = pool.starmap(Component_eval_10cv,tasks)\n",
    "# np.save(f'{data_dir}/Component_eval_10cv_{times}times', ans) \n",
    "# cores = multiprocessing.cpu_count()\n",
    "# pool = multiprocessing.Pool(processes=cores)\n",
    "\n",
    "# times = 60\n",
    "# tasks = [[x] for x in range(51,times+1)]\n",
    "# print(tasks)\n",
    "# ans = pool.starmap(Component_eval_10cv,tasks)\n",
    "# np.save(f'{data_dir}/Component_eval_10cv_{times}times', ans) \n",
    "# cores = multiprocessing.cpu_count()\n",
    "# pool = multiprocessing.Pool(processes=cores)\n",
    "\n",
    "# times = 70\n",
    "# tasks = [[x] for x in range(61,times+1)]\n",
    "# print(tasks)\n",
    "# ans = pool.starmap(Component_eval_10cv,tasks)\n",
    "# np.save(f'{data_dir}/Component_eval_10cv_{times}times', ans) \n",
    "# cores = multiprocessing.cpu_count()\n",
    "# pool = multiprocessing.Pool(processes=cores)\n",
    "\n",
    "# times = 80\n",
    "# tasks = [[x] for x in range(71,times+1)]\n",
    "# print(tasks)\n",
    "# ans = pool.starmap(Component_eval_10cv,tasks)\n",
    "# np.save(f'{data_dir}/Component_eval_10cv_{times}times', ans) \n",
    "# cores = multiprocessing.cpu_count()\n",
    "# pool = multiprocessing.Pool(processes=cores)\n",
    "\n",
    "# times = 90\n",
    "# tasks = [[x] for x in range(81,times+1)]\n",
    "# print(tasks)\n",
    "# ans = pool.starmap(Component_eval_10cv,tasks)\n",
    "# np.save(f'{data_dir}/Component_eval_10cv_{times}times', ans) \n",
    "# cores = multiprocessing.cpu_count()\n",
    "# pool = multiprocessing.Pool(processes=cores)\n",
    "\n",
    "# times = 100\n",
    "# tasks = [[x] for x in range(91,times+1)]\n",
    "# print(tasks)\n",
    "# ans = pool.starmap(Component_eval_10cv,tasks)\n",
    "# np.save(f'{data_dir}/Component_eval_10cv_{times}times', ans) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpsheets = sorted(glob(f'{data_dir}/Component_eval_10cv_*times.npy'))\n",
    "df = pd.DataFrame()\n",
    "for sheet in xpsheets:\n",
    "    ans = np.load(sheet, allow_pickle=True)\n",
    "    for x in range(len(ans)):\n",
    "        print(x)\n",
    "        preds_cur = ans[x][2]\n",
    "        df_cur = pd.DataFrame(columns = [\"Component_9fold_bymse\", \"Correlation\"])\n",
    "        df_cur.Component_9fold_bymse = ans[x][0]\n",
    "        df_cur.Correlation = np.array(ans[x][1])\n",
    "        df = pd.concat([df, df_cur], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_strategy=100\n",
    "# r_nc.index=range(1,cv_strategy+1)\n",
    "# r_nc_toplot = pd.concat([r_nc.T.iloc[:,x] for x in range(len(r_nc))], axis=0)\n",
    "r_nc_plot = pd.DataFrame({'cn':df.Component_9fold_bymse, '100*10cv_score':abs(df.Correlation.values)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cn in r_nc_plot.cn.unique():\n",
    "    print(cn)\n",
    "    print(np.mean(r_nc_plot.loc[r_nc_plot.cn == cn,'100*10cv_score']))\n",
    "    print(np.median(r_nc_plot.loc[r_nc_plot.cn == cn,'100*10cv_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RdBu_200 = cm.get_cmap('RdBu', 200)(np.arange(200))\n",
    "cm.get_cmap('RdBu', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,10))\n",
    "# # 默认主轴图axes是subplot(111)\n",
    "# my_pal = {cn: \"#0E437C\" if cn == 6 else \"#2E5996\" for cn in r_nc_plot.cn.unique()}\n",
    "\n",
    "my_pal = {cn: RdBu_200[30] if cn == 6 else RdBu_200[185] for cn in r_nc_plot.cn.unique()}\n",
    "# my_pal = {cn: jet_9[7] if cn == 6 else jet_9[1] for cn in r_nc_plot.cn.unique()}\n",
    "sns.boxplot(x=\"cn\", y='100*10cv_score', data=r_nc_plot, showfliers=False, palette=my_pal, width = 0.8, showmeans=True, \n",
    "            boxprops = { 'edgecolor':'grey'},\n",
    "            meanprops={\"marker\":\"o\", \"markersize\":\"10\", \"markerfacecolor\":\"white\",  \"linewidth\":1, \"markeredgecolor\":\"black\"},\n",
    "            medianprops={\"color\":\"grey\", \"linewidth\":2},\n",
    "            whiskerprops={\"color\":\"grey\", \"linewidth\":2},\n",
    "            capprops={\"color\":\"grey\", \"linewidth\":2}) # palette=\"hls\"\n",
    "sns.swarmplot(x=\"cn\", y='100*10cv_score', data=r_nc_plot, color ='gray',size = 4, alpha=0.66)\n",
    "sns.despine()\n",
    "plt.ylim(0, 0.8)\n",
    "plt.yticks([0,0.2,0.4,0.6,0.8], fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.xlabel('Component number', fontsize=25)\n",
    "plt.ylabel(\"Correlation\", fontsize=25)\n",
    "\n",
    "fig_name = 'Cere_02_PLSR_CV_component_cere2etra_100x10cv_Kris.png'\n",
    "plt.savefig(os.path.join(fig_dir, fig_name), dpi=500, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def PLSR_pipeline(in_mtx, y, \n",
    "                    clf = linear_model.LassoCV(random_state = 123), \n",
    "                    cv_strategy = None, cv = 10, test_gene_num = [100], illustrative = False,\n",
    "                   sanity_check_style = 'separate', cv_labels = [], reverse_axes = True):\n",
    "    \n",
    "    final_outputs = {}\n",
    "    \n",
    "    if type(in_mtx) == pandas.core.frame.DataFrame:\n",
    "        in_mtx = in_mtx.values\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('performing model cross-validation')\n",
    "    print('using basic %s-fold cross-validation'%cv)\n",
    "    #scores = model_selection.cross_val_score(clf, in_mtx, y=y, cv=cv)\n",
    "    predicted = model_selection.cross_val_predict(clf, in_mtx, y=y, cv=cv, n_jobs=-1)\n",
    "    observed = y\n",
    "    try:\n",
    "        score = abs(stats.pearsonr(predicted, y)[0])\n",
    "    except:\n",
    "        score = abs(stats.pearsonr(predicted[:,0], y)[0])\n",
    "    else:\n",
    "        score = None\n",
    "\n",
    "\n",
    "    plt.close()\n",
    "    plt.scatter(predicted, observed)\n",
    "    # sns.regplot(predicted, observed, fit_reg=False)\n",
    "    plt.xlabel('CV model predicted FG along axis')\n",
    "    plt.ylabel('Actual FG')\n",
    "    plt.show()\n",
    "    print('model cv score: r = ',score)\n",
    "    final_outputs.update({'CV_scores': score})\n",
    "\n",
    "    \n",
    "    print('running final model')\n",
    "    mod = clf.fit(in_mtx, y)\n",
    "    if not hasattr(mod,'coef_'):\n",
    "        raise IOError('right now, this pipeline can only accept clf objects with a coef_ attribute')\n",
    "    final_outputs.update({'final_model': mod})\n",
    "    scr = mod.score(in_mtx, y) \n",
    "    print('final model fit r = ',scr)\n",
    "    if illustrative:\n",
    "        plt.close()\n",
    "        sns.regplot(x=mod.predict(in_mtx), y=y)\n",
    "        plt.xlabel('Model predicted FG')\n",
    "        plt.ylabel('Actual FG')\n",
    "        plt.show()\n",
    "    final_outputs.update({'betas': mod.coef_})\n",
    "    \n",
    "    gene_selections = sanity_check(in_mtx, y, mod.coef_, test_gene_num, \n",
    "                                   illustrative, sanity_check_style, reverse_axes)\n",
    "    final_outputs.update({'gene_selections': gene_selections})\n",
    "    \n",
    "    return final_outputs\n",
    "\n",
    "\n",
    "def sanity_check(in_mtx, y, betas, test_gene_num, illustrative, \n",
    "                 sanity_check_style, reverse_axes):\n",
    "    \n",
    "    if sanity_check_style == 'separate':\n",
    "        ascores = []\n",
    "        pscores = []\n",
    "    else:\n",
    "        scores = []\n",
    "    print('running sanity_check')\n",
    "    try:\n",
    "        betas = pandas.Series(betas)\n",
    "    except:\n",
    "        betas = pandas.Series(betas[:,0])\n",
    "    outputs = {}\n",
    "    for num in test_gene_num:\n",
    "      \n",
    "        p_chk = betas.sort_values(ascending=False)[:num].index\n",
    "        a_chk = betas.sort_values(ascending=False)[-num:].index\n",
    "\n",
    "        pchk_vals = []\n",
    "        achk_vals = []\n",
    "        \n",
    "        for sample in range(in_mtx.shape[0]):\n",
    "            to_avg = []\n",
    "            for gene in p_chk:\n",
    "                to_avg.append(in_mtx[sample,gene])\n",
    "            if sanity_check_style == 'model':\n",
    "                pchk_vals.append(np.mean(np.array(to_avg) * betas.loc[p_chk].values))\n",
    "            else:\n",
    "                pchk_vals.append(np.mean(to_avg))\n",
    "        \n",
    "        for sample in range(in_mtx.shape[0]):\n",
    "            to_avg = []\n",
    "            for gene in a_chk:\n",
    "                to_avg.append(in_mtx[sample,gene])\n",
    "            if sanity_check_style == 'separate':\n",
    "                achk_vals.append(np.mean(to_avg))\n",
    "            elif sanity_check_style == 'model':\n",
    "                achk_vals.append(np.mean(np.array(to_avg) * betas.loc[a_chk].values))\n",
    "            else:\n",
    "                achk_vals.append(np.mean(to_avg) * -1)\n",
    "\n",
    "        if sanity_check_style != 'separate':\n",
    "            chk_vals = np.array(pchk_vals) + np.array(achk_vals)\n",
    "            \n",
    "        if sanity_check_style == 'separate':\n",
    "            pr,pp = stats.pearsonr(pchk_vals, y)\n",
    "            if illustrative:\n",
    "                plt.close()\n",
    "                sns.regplot(x=np.array(pchk_vals), y=y, fit_reg=None)\n",
    "                if reverse_axes:\n",
    "                    plt.xlabel('expression of anterior direction genes')\n",
    "                    plt.ylabel('Actual FG')\n",
    "                    plt.show()\n",
    "                    print('anterior %s genes vs. y:  r = %s, p = %s \\n\\n'%(num, pr, pp))\n",
    "                else:\n",
    "                    plt.xlabel('expression of posterior direction genes')\n",
    "                    plt.ylabel('Actual FG')\n",
    "                    plt.show()\n",
    "                    print('posterior %s genes vs. y:  r = %s, p = %s \\n\\n'%(num, pr, pp))\n",
    "\n",
    "            ar,ap = stats.pearsonr(achk_vals, y)\n",
    "            if illustrative:\n",
    "                plt.close()\n",
    "                sns.regplot(x=np.array(achk_vals), y=y, fit_reg=None)\n",
    "                if reverse_axes:\n",
    "                    plt.xlabel('expression of posterior direction genes')\n",
    "                    plt.ylabel('Actual FG')\n",
    "                    plt.show()\n",
    "                    print('posterior %s genes vs. y:  r = %s, p = %s \\n\\n'%(num, ar, ap))\n",
    "                else:\n",
    "                    plt.xlabel('expression of anterior direction genes')\n",
    "                    plt.ylabel('Actual FG')\n",
    "                    plt.show()\n",
    "                    print('anterior %s genes vs. y:  r = %s, p = %s \\n\\n'%(num, ar, ap))\n",
    "            \n",
    "        else:\n",
    "            r,p = stats.pearsonr(chk_vals, y)\n",
    "            if illustrative:\n",
    "                plt.close()\n",
    "                sns.regplot(x=np.array(chk_vals), y=y, fit_reg=None)\n",
    "                plt.xlabel('expression of A-P axis genes')\n",
    "                if reverse_axes:\n",
    "                    plt.ylabel('Actual FG')\n",
    "                else:\n",
    "                    plt.ylabel('Actual FG')\n",
    "                plt.show()\n",
    "                print('posterior and anterior %s genes vs. y:  r = %s, p = %s \\n\\n'%(\n",
    "                                                                                num, r, p))\n",
    "            \n",
    "        if sanity_check_style == 'separate':\n",
    "            if reverse_axes:\n",
    "                ascores.append(pr)\n",
    "                pscores.append(ar)\n",
    "            else:\n",
    "                ascores.append(ar)\n",
    "                pscores.append(pr)\n",
    "        else:\n",
    "            scores.append(r)\n",
    "        if reverse_axes:\n",
    "            outputs.update({'posterior_genes_%s'%num: a_chk}) \n",
    "            outputs.update({'anterior_genes_%s'%num: p_chk})\n",
    "        else:\n",
    "            outputs.update({'posterior_genes_%s'%num: p_chk}) \n",
    "            outputs.update({'anterior_genes_%s'%num: a_chk})\n",
    "            \n",
    "    if len(test_gene_num) > 1:\n",
    "        if sanity_check_style == 'separate':\n",
    "            jnk = pandas.concat([pandas.concat([pandas.Series(test_gene_num), pandas.Series(test_gene_num)], axis = 0),\n",
    "                  pandas.concat([pandas.Series(ascores), pandas.Series(pscores)], axis = 0),\n",
    "                  pandas.concat([pandas.Series(['a']*len(test_gene_num)), pandas.Series(['p']*len(test_gene_num))], axis = 0)\n",
    "                  ],axis = 1)\n",
    "            jnk.columns = ['num','score','class']\n",
    "            jnk['num'] = jnk['num'].astype('category')\n",
    "            plt.close()\n",
    "            # plt.figure(figsize=(7,7))\n",
    "            sns.catplot(x='num', y='score', data=jnk, hue = 'class',\n",
    "                        palette={\"a\": \"g\", \"p\": \"m\"}, aspect=2, size=5)\n",
    "            plt.xlabel('Number of top genes')\n",
    "            plt.ylabel('Prediction score')\n",
    "            plt.show()\n",
    "        else:\n",
    "            jnk = pandas.concat([pandas.Series(test_gene_num), \n",
    "                                 pandas.Series(scores)\n",
    "                                ],axis=1)\n",
    "            jnk.columns = ['num','score']\n",
    "            jnk['num'] = jnk['num'].astype('category')\n",
    "\n",
    "            plt.close()\n",
    "            fig,ax1 = plt.subplots(1, figsize=(8,10))\n",
    "            sns.catplot(x='num', y='score', data=jnk, ax=ax1)\n",
    "            ax1.set(xlabel = 'Number of genes', \n",
    "                    ylabel ='Explained variance in \\nhippocampus a-p gradient')\n",
    "            plt.show()\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pls_out = PLSR_pipeline(expression,\n",
    "                        report['gradient1'], \n",
    "                        clf = PLSRegression(n_components=6),\n",
    "                        cv_strategy='score', \n",
    "                        illustrative=True,\n",
    "                        test_gene_num = [1, 2, 5, 10, 20, 50, 100,  # sanity check\n",
    "                                              200, 500, 1000, 2000, 5000],\n",
    "                        sanity_check_style = 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORE = abs(stats.pearsonr(pls_out['final_model'].predict(expression).flatten(), report['gradient1'])[0]) # 0.8221736006902771\n",
    "EVS_cn6 = explained_variance_score(pls_out['final_model'].predict(expression), report['gradient1']) # 0.5206431591363406"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 101 * 10cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#region\n",
    "# def Eval_10cv_101times(cv_s):\n",
    "#     clf = PLSRegression(n_components=6)\n",
    "#     cv=10\n",
    "#     y = report['gradient1']\n",
    "#     preds_cur = pandas.DataFrame(np.zeros((len(y),1)))\n",
    "#     preds_cur.index = expression.index\n",
    "#     r_cur = pandas.DataFrame(np.zeros((1,cv)))\n",
    "#     sel = model_selection.KFold(n_splits=cv, shuffle=True, random_state=(123 * (cv_s+1)))\n",
    "#     fold=0\n",
    "#     for tr_ind, te_ind in sel.split(expression):\n",
    "#         tr_cols = expression.index[tr_ind]\n",
    "#         tr_set = pandas.DataFrame(expression.loc[tr_cols,:], copy=True)\n",
    "#         tr_y = pandas.DataFrame(report['gradient1']).iloc[tr_ind,:]\n",
    "#         te_cols = expression.index[te_ind]\n",
    "#         te_set = pandas.DataFrame(expression.loc[te_cols,:], copy=True)\n",
    "#         te_y = pandas.DataFrame(report['gradient1']).iloc[te_ind,:]\n",
    "#         mod = clf.fit(tr_set,tr_y)\n",
    "#         preds_cur.loc[te_cols, i] = mod.predict(te_set).flatten()\n",
    "#         r_cur.loc[:,fold] =stats.pearsonr(te_y.values.flatten(), mod.predict(te_set).flatten())[0]\n",
    "#         fold += 1\n",
    "#         print('completed iteration',i+1)\n",
    "#     return r_cur, preds_cur\n",
    "\n",
    "# cores = multiprocessing.cpu_count()\n",
    "# pool = multiprocessing.Pool(processes=cores)\n",
    "\n",
    "# cv_strategy=101\n",
    "# tasks = [[x] for x in range(1,cv_strategy)]\n",
    "# ans = pool.starmap(Eval_10cv_101times,tasks)\n",
    "# r_101 = pd.concat([pd.DataFrame(ans[x]) for x in range(len(ans))], axis=0)\n",
    "# r_101.index=range(1,ncs+1)\n",
    "# r_10.to_csv(os.path.join(data_dir, 'PLS_Component_eval_10cv_test.csv'))\n",
    "\n",
    "# def Eval_10cv_predicts(cv_times): \n",
    "#     y = report['gradient1']\n",
    "#     preds_10 = pandas.DataFrame(np.zeros((len(y),1)))\n",
    "#     preds_10.index = expression.index\n",
    "#     clf = PLSRegression(n_components=6)\n",
    "#     cv=10\n",
    "#     sel = model_selection.KFold(n_splits=cv, shuffle=True, random_state=(123 * (cv_times+1)))\n",
    "#     fold=0\n",
    "#     for tr_ind, te_ind in sel.split(expression):\n",
    "#         # print('working on fold',fold)\n",
    "#         tr_cols = expression.index[tr_ind]\n",
    "#         tr_set = pandas.DataFrame(expression.loc[tr_cols,:], copy=True)\n",
    "#         tr_y = pandas.DataFrame(report['gradient1']).iloc[tr_ind,:]\n",
    "#         te_cols = expression.index[te_ind]\n",
    "#         te_set = pandas.DataFrame(expression.loc[te_cols,:], copy=True)\n",
    "#         te_y = pandas.DataFrame(report['gradient1']).iloc[te_ind,:]\n",
    "#         mod = clf.fit(tr_set,tr_y)\n",
    "#         preds_10.loc[te_cols, :] = mod.predict(te_set)\n",
    "#         fold += 1\n",
    "#     print('completed iteration',i+1)\n",
    "#     return preds_10\n",
    "\n",
    "# cores = multiprocessing.cpu_count()\n",
    "# pool = multiprocessing.Pool(processes=cores)\n",
    "\n",
    "# cv_strategy=100\n",
    "# y = report['gradient1']\n",
    "# preds_100 = pandas.DataFrame(np.zeros((len(y),cv_strategy)))\n",
    "# preds_100.columns = range(cv_strategy)\n",
    "# preds_100.index = expression.index\n",
    "\n",
    "# for cv_s in range(10,110,10):\n",
    "#     tasks = [[x] for x in range(cv_s-10, cv_s)]\n",
    "#     print(tasks)\n",
    "#     ans = pool.starmap(Eval_10cv_predicts,tasks) \n",
    "#     preds_100.iloc[:, range(cv_s-10, cv_s)] = pd.concat([pd.DataFrame(ans[x]) for x in range(len(ans))], axis=1)\n",
    "#endregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 101*10cv\n",
    "clf = PLSRegression(n_components=6)\n",
    "cv=10\n",
    "cv_strategy=101\n",
    "y = report['gradient1']\n",
    "score = []\n",
    "# preds_101 = pandas.DataFrame(np.zeros((len(y),cv_strategy)))\n",
    "# preds_101.columns = range(cv_strategy)\n",
    "# preds_101.index = expression.index\n",
    "# r_101 = pandas.DataFrame(np.zeros((cv,cv_strategy)))\n",
    "# r_101.columns = range(cv_strategy)\n",
    "\n",
    "# for i in range(cv_strategy):\n",
    "#     print(i)\n",
    "#     sel = model_selection.KFold(n_splits=cv, shuffle=True, random_state=(123 * (i+1)))\n",
    "#     fold=0\n",
    "#     for tr_ind, te_ind in sel.split(expression):\n",
    "#         # print('working on fold',fold)\n",
    "#         tr_cols = expression.index[tr_ind]\n",
    "#         tr_set = pandas.DataFrame(expression.loc[tr_cols,:], copy=True)\n",
    "#         tr_y = pandas.DataFrame(report['gradient1']).iloc[tr_ind,:]\n",
    "#         te_cols = expression.index[te_ind]\n",
    "#         te_set = pandas.DataFrame(expression.loc[te_cols,:], copy=True)\n",
    "#         te_y = pandas.DataFrame(report['gradient1']).iloc[te_ind,:]\n",
    "#         mod = clf.fit(tr_set,tr_y)\n",
    "#         preds_101.loc[te_cols, i] = mod.predict(te_set).flatten()\n",
    "#         r_101.loc[fold,i] = stats.pearsonr(te_y.values.flatten(), mod.predict(te_set).flatten())[0]\n",
    "#         fold += 1\n",
    "#     # print('completed iteration',i+1)\n",
    "# pandas.DataFrame(preds_101).to_csv(os.path.join(data_dir, 'Cere_02_PLS_101*10cv_cere2extra_preds.csv'))\n",
    "# pandas.DataFrame(r_101).to_csv(os.path.join(data_dir, 'Cere_02_PLS_101*10cv_cere2extra_r_1fold.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Final whole \n",
    "plt.close()\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "sns.regplot(x=report['gradient1'], y=pls_out['final_model'].predict(expression), ci = 95, \n",
    "            scatter_kws={'s': 50, 'linewidths': 1, 'color':Hex_1[1]},\n",
    "            line_kws={'linewidth':3, 'color':Hex_1[1]}) # 'color':'b'\n",
    "sns.despine()\n",
    "plt.xlim(0,1.0)\n",
    "plt.xticks([0,0.5,1])\n",
    "plt.xlabel('Actual FG', fontsize = 20)\n",
    "plt.ylim(-0.3,1.3)\n",
    "plt.yticks([0,0.5,1])\n",
    "plt.ylabel('Predicted FG')\n",
    "r = np.float16(stats.pearsonr(pls_out['final_model'].predict(expression).flatten(),report['gradient1'])[0]) # 0.6682418831405792, 1.751126236923602e-34\n",
    "plt.text(0.05, 1.0,'r = %s'%(float('%.2g' % r)), fontsize=30)\n",
    "fig_name = 'Cere_02_PLS_Final_cere2extra.png'\n",
    "plt.savefig(os.path.join(fig_dir,fig_name), dpi=500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No large difference between sklearn and matlab default plsr\n",
    "# Try the plsr model from matlab\n",
    "from pyls.types.regression import simpls\n",
    "X = expression.values\n",
    "Y = report['gradient1'].values.reshape([-1,1])\n",
    "plsr_true = simpls(X=X, Y=Y, n_components=6, seed=123) # dict_keys(['x_weights', 'x_loadings', 'y_loadings', 'x_scores', 'y_scores', 'x_residuals', 'y_residuals', 'beta', 'pctvar', 'mse', 't2'])\n",
    "np.sum(plsr_true['pctvar'][1]) # Accumulated explained variance for 6 components X: 0.4162980356606241; Y: 0.6646998385364935\n",
    "preds = np.dot(np.concatenate((np.ones((317,1)), X), axis=1), plsr_true['beta'])  \n",
    "\n",
    "plt.close()\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "sns.regplot(x=report['gradient1'], y=preds, ci = 95, \n",
    "            scatter_kws={'s': 50, 'linewidths': 1, 'color':Hex_1[1]},\n",
    "            line_kws={'linewidth':3, 'color':Hex_1[1]}) # 'color':'b'\n",
    "sns.despine()\n",
    "plt.xlim(0,1.0)\n",
    "plt.xticks([0,0.5,1])\n",
    "plt.xlabel('Actual FG', fontsize = 20)\n",
    "plt.ylim(-0.3,1.3)\n",
    "plt.yticks([0,0.5,1])\n",
    "plt.ylabel('Predicted FG', fontsize = 20)\n",
    "r = np.float16(stats.pearsonr(preds.flatten(),report['gradient1'])[0]) # 0.6682418831405792, 1.751126236923602e-34\n",
    "# np.float16(stats.pearsonr(preds.flatten(),report['gradient1'])[0])\n",
    "plt.text(0.05, 1.0, f'r = {r}', fontsize=30)\n",
    "# fig_name = 'Cere_02_PLS_Final_cere2extra.png'\n",
    "# plt.savefig(os.path.join(fig_dir,fig_name), dpi=500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brainsmash to test the signifcance of 101*10cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the median model\n",
    "y = report['gradient1']\n",
    "cv_strategy=101\n",
    "preds_101 = pandas.read_csv(os.path.join(data_dir,'Cere_02_PLS_101*10cv_cere2extra_preds.csv'), index_col=0)\n",
    "score_true = []\n",
    "for i in range(cv_strategy):\n",
    "    score_true.append(stats.pearsonr(preds_101.iloc[:,i].values, report['gradient1'])[0])\n",
    "score_df = pandas.DataFrame(score_true)\n",
    "# model_index = [score_df.sort_values(by=0).index[50], score_df.sort_values(by=0).index[49]]\n",
    "model_index = score_df.sort_values(by=0).index[50]  # 44\n",
    "\n",
    "np.float64(stats.pearsonr(preds_101.iloc[:,44], report['gradient1'])[0]), float('%.16g' % np.median(score))\n",
    "\n",
    "xpsheets_name = f'{data_dir}/Permutation/cere_317samples_genelevel/PLS_Score_BrainSmash_Value_Y_17853_*000_101*10cv_preds_44.csv'\n",
    "csv_list = sorted(glob(xpsheets_name))\n",
    "Final_perm_cur = pd.Series()\n",
    "for f in csv_list:\n",
    "    # num_id = int(f.split('_')[-1].split('.')[0])\n",
    "    csv_cur = pandas.read_csv(f, index_col=0)\n",
    "    value_cur = [stats.pearsonr(report['gradient1'], csv_cur.iloc[:, x])[0] for x in range(len(csv_cur.T))]\n",
    "    # print(csv_cur)\n",
    "    Final_perm_cur = pd.concat((Final_perm_cur, pd.Series(value_cur)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "RdBu_Hex = [mpl.colors.to_hex(x) for x in np.flipud(cm.get_cmap('RdBu')(np.linspace(0,1,200)))[:,0:3]]\n",
    "RdBu_Hex = RdBu_Hex[: :-1]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot\n",
    "## r2median\n",
    "preds_101 = pandas.read_csv(os.path.join(data_dir,'Cere_02_PLS_101*10cv_cere2extra_preds.csv'), index_col=0)\n",
    "plt.close()\n",
    "fig = plt.figure(figsize=(12,10))\n",
    "\n",
    "score = []\n",
    "for i in range(cv_strategy):\n",
    "    score.append(stats.pearsonr(preds_101.iloc[:,i].values, report['gradient1'])[0])\n",
    "jnk = pandas.DataFrame(index = range(cv_strategy), \n",
    "                       columns = ['score','iteration'])\n",
    "jnk.loc[:,'iteration'] = list(range(cv_strategy))\n",
    "jnk.loc[:,'score'] = score\n",
    "sns.distplot(score, 15, kde=True, rug=True,\n",
    "             kde_kws={\"color\": RdBu_200[185], \"lw\":3 }, \n",
    "             hist_kws={ \"color\": RdBu_200[185], 'alpha': .7 })\n",
    "sns.despine()\n",
    "plt.xlim(0.4, 0.5)\n",
    "plt.xticks([0.4,0.42,0.44,0.46,0.48,0.50], fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "ylim = plt.ylim()\n",
    "plt.vlines(np.median(score), ylim[0], ylim[1], linestyle='-',\n",
    "           color=jet_9[0], linewidth=4)\n",
    "plt.text(np.median(score)-0.03, 33.5,'Median=%s'%(float('%.2g' % np.median(score))), \n",
    "         fontsize=30)\n",
    "plt.ylabel('Density', fontsize=25)\n",
    "plt.xlabel('R between predicted and true FG1', fontsize=25)\n",
    "fig_name = 'Cere_02_PLS_101x10cv_cere2extra_r2median.png'\n",
    "plt.savefig(os.path.join(fig_dir, fig_name),  dpi=500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the median model\n",
    "fig = plt.figure(figsize=(12,10))\n",
    "sns.set_context('paper', font_scale=2.5)\n",
    "sns.set_style('ticks')\n",
    "sns.regplot(x=report['gradient1'], y=preds_101.iloc[:,44], fit_reg=True, \n",
    "            scatter_kws={'s': 50, 'linewidths': 1, 'color':RdBu_Hex[185]},\n",
    "            line_kws={'linewidth':4, 'color': RdBu_Hex[195]}) # 'color':'b'\n",
    "sns.despine()\n",
    "plt.xlim(0,1.0)\n",
    "plt.ylim(-0.12,1.1)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.xlabel('Actual FG', fontsize=25)\n",
    "plt.ylabel('Predicted FG', fontsize=25)\n",
    "r = np.float16(stats.pearsonr(preds_101.iloc[:,44], report['gradient1'])[0])\n",
    "plt.text(0.05, 0.92,'$r=%s, p_{SA}<0.01$'%(float('%.2g' % r)), fontsize=30)\n",
    "fig_name = 'Cere_02_PLS_101x10cv_cere2extra_model44.png'\n",
    "plt.savefig(os.path.join(fig_dir, fig_name),  dpi=500, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,1.2))\n",
    "sns.set_context('paper', font_scale=2.5)\n",
    "sns.set_style('ticks')\n",
    "\n",
    "a = plt.axes([.73, .14, 0.13, 0.2])\n",
    "sns.distplot(Final_perm_cur, 15, kde=True, rug=True, #hist=True, kde=False, rug=False,\n",
    "             kde_kws={\"color\":RdBu_200[185], \"lw\":3 }, \n",
    "             hist_kws={ \"color\": RdBu_200[185], 'alpha': .7 })\n",
    "sns.despine()\n",
    "ylim = plt.ylim()\n",
    "plt.vlines(0.4571185433269431, ylim[0], ylim[1], linestyle='-',\n",
    "           color=jet_9[0], linewidth=3, label='Actural r')\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.ylabel(\"Frequency\", fontsize=12)\n",
    "plt.text(0.15, 2.2,'Actural r', fontsize=12)\n",
    "\n",
    "fig_name = 'Cere_02_PLS_101x10cv_cere2extra_model44_permutation.png'\n",
    "plt.savefig(os.path.join(fig_dir, fig_name),  dpi=500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot\n",
    "## r2median\n",
    "preds_101 = pandas.read_csv(os.path.join(data_dir,'Cere_02_PLS_101*10cv_cere2extra_preds.csv'), index_col=0)\n",
    "plt.close()\n",
    "fig = plt.figure(figsize=(24,10))\n",
    "\n",
    "plt.subplot(121)\n",
    "sns.set_context('poster',font_scale=0.8)\n",
    "score = []\n",
    "for i in range(cv_strategy):\n",
    "    score.append(stats.pearsonr(preds_101.iloc[:,i].values, report['gradient1'])[0])\n",
    "jnk = pandas.DataFrame(index = range(cv_strategy), \n",
    "                       columns = ['score','iteration'])\n",
    "jnk.loc[:,'iteration'] = list(range(cv_strategy))\n",
    "jnk.loc[:,'score'] = score\n",
    "sns.distplot(score, 15, kde=True, rug=True,\n",
    "             kde_kws={\"color\": RdBu_200[185], \"lw\":3 }, \n",
    "             hist_kws={ \"color\": RdBu_200[185], 'alpha': .7 })\n",
    "sns.despine()\n",
    "plt.xlim(0.4, 0.5)\n",
    "plt.xticks([0.4,0.42,0.44,0.46,0.48,0.50], fontsize=20)\n",
    "\n",
    "\n",
    "plt.yticks(fontsize=20)\n",
    "ylim = plt.ylim()\n",
    "plt.vlines(np.median(score), ylim[0], ylim[1], linestyle='-',\n",
    "           color=RdBu_200[185], linewidth=8)\n",
    "plt.text(np.median(score)-0.034, 33.5,'Median=%s'%(float('%.2g' % np.median(score))), \n",
    "         fontsize=30)\n",
    "plt.ylabel('Density', fontsize=25)\n",
    "plt.xlabel('R between predicted and true FG1', fontsize=25)\n",
    "ax = plt.gca()\n",
    "ax.spines['bottom'].set_linewidth(2)\n",
    "ax.spines['left'].set_linewidth(2)\n",
    "# fig_name = 'Cere_02_PLS_101x10cv_cere2extra_r2median.png'\n",
    "# plt.savefig(os.path.join(fig_dir, fig_name),  dpi=500, bbox_inches='tight')\n",
    "# plt.show()\n",
    "\n",
    "# Plot the median model\n",
    "# fig = plt.figure(figsize=(10,10))\n",
    "plt.subplot(122)\n",
    "sns.set_context('paper', font_scale=0.8)\n",
    "sns.set_style('ticks')\n",
    "sns.regplot(x=report['gradient1'], y=preds_101.iloc[:,44], fit_reg=True, \n",
    "            scatter_kws={'s': 50, 'linewidths': 1, 'color':RdBu_Hex[185]},\n",
    "            line_kws={'linewidth':4, 'color': RdBu_Hex[195]}) # 'color':'b'\n",
    "sns.despine()\n",
    "plt.xlim(0,1.0,)\n",
    "plt.ylim(-0.12,1.1)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.xlabel('Actual FG', fontsize=25)\n",
    "plt.ylabel('Predicted FG', fontsize=25)\n",
    "r = np.float16(stats.pearsonr(preds_101.iloc[:,44], report['gradient1'])[0])\n",
    "plt.text(0.05, 0.92,'$r=%s, p_{SA}<0.01$'%(float('%.2g' % r)), fontsize=30)\n",
    "ax = plt.gca()\n",
    "ax.spines['bottom'].set_linewidth(2)\n",
    "ax.spines['left'].set_linewidth(2)\n",
    "\n",
    "\n",
    "a = plt.axes([.73, .14, 0.13, 0.2])\n",
    "sns.distplot(Final_perm_cur, 15, kde=True, rug=True, #hist=True, kde=False, rug=False,\n",
    "             kde_kws={\"color\":RdBu_200[185], \"lw\":3 }, \n",
    "             hist_kws={ \"color\": RdBu_200[185], 'alpha': .7 })\n",
    "sns.despine()\n",
    "ylim = plt.ylim()\n",
    "plt.vlines(0.4571185433269431, ylim[0], ylim[1], linestyle='-',\n",
    "           color=RdBu_200[185], linewidth=4, label='Actural r')\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.ylabel(\"Density\", fontsize=12)\n",
    "plt.text(0.16, 2.2,'Actural r', fontsize=12)\n",
    "\n",
    "fig_name = 'Cere_02_PLS_101x10cv_cere2extra_r2median+model44.png'\n",
    "plt.savefig(os.path.join(fig_dir, fig_name),  dpi=700, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = pls_out['final_model'].predict(expression)\n",
    "\n",
    "jnk = pandas.concat([pandas.Series(map(lambda x: x[0], predicted)),\n",
    "                     pandas.Series(report['gradient1'].values),\n",
    "                     pandas.Series(report['donor'].values)], \n",
    "                     axis=1)\n",
    "jnk.columns = ['predicted','observed','Donor']\n",
    "\n",
    "plt.close()\n",
    "# plt.figure(figsize=(10,10))\n",
    "g = sns.lmplot(x='observed', y='predicted', hue='Donor', data=jnk, fit_reg=True, height=10, aspect=1.6,\n",
    "               scatter_kws = {'s': 66,  'edgecolor': 'none'}, # 'alpha': 0.5,\n",
    "               line_kws ={'linewidth': 3})  # palette=Hex_1\n",
    "g.fig.set_size_inches(10,10)\n",
    "leg = g._legend\n",
    "leg.set_bbox_to_anchor([0.35,0.75])\n",
    "# ax.legend(title='Donor', bbox_to_anchor=(1.05, 1))\n",
    "plt.xlim(0,1.0)\n",
    "plt.xticks([0,0.5,1])\n",
    "plt.xlabel('Actual FG', fontsize = 20)\n",
    "plt.ylim(-0.3,1.3)\n",
    "plt.yticks([0,0.5,1])\n",
    "plt.ylabel('Predicted FG', fontsize = 20)\n",
    "# plt.xticks(range(0,0.6))\n",
    "fig_name = 'Cere_02_PLS_allsub.png'\n",
    "plt.savefig(os.path.join(fig_dir,fig_name), \n",
    "            dpi=500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "clf = PLSRegression(n_components=6)\n",
    "\n",
    "plt.close()\n",
    "# plt.figure(figsize=(5,30))\n",
    "fig,axes= plt.subplots(6,1, figsize=(10,60), gridspec_kw={'height_ratios': [1, 1, 1, 1, 1, 1]})\n",
    "for i, subject in enumerate(report.donor.unique()):\n",
    "    Tr_samps = report[report['donor']!=subject].index  # ID samples from training sample (not the donor)\n",
    "    Te_samps = report[report['donor']==subject].index  # ID samples from the test sample (the donor)\n",
    "    # Set X and y\n",
    "    X = expression[expression.index.isin(Tr_samps)]\n",
    "    FG = pandas.DataFrame(report['gradient1'])\n",
    "    FG.index = report.index\n",
    "    y = FG[FG.index.isin(Tr_samps)]\n",
    "    # get size of training and test\n",
    "    nX = len(Te_samps)\n",
    "    nT = len(Tr_samps)\n",
    "    # run model\n",
    "    mod = clf.fit(X,y)\n",
    "    # predict axis location for samples from the left-out donor\n",
    "    pred = mod.predict(expression[expression.index.isin(Te_samps)])\n",
    "    \n",
    "    # plot it\n",
    "    sns.set_context('poster', font_scale=0.8)\n",
    "    sns.set_style('ticks')\n",
    "    sns.regplot(x=FG[FG.index.isin(Te_samps)], y=pred, ax=axes[i], fit_reg=True, \n",
    "                scatter_kws={'s': 50, 'linewidths': 1, 'color':Hex_1[1]},\n",
    "                line_kws={'linewidth':4, 'color':Hex_1[2]})\n",
    "    sns.despine()\n",
    "    axes[i].set_title(subject, fontdict = {'size':25})\n",
    "    axes[i].set_xlim(0, np.max(FG[FG.index.isin(Te_samps)]).values+0.05)\n",
    "    axes[i].set_xticks([0, 0.2, 0.4, 0.6, 0.8])\n",
    "    axes[i].set_ylim(np.min(pred)-0.05,np.max(pred)+0.05)\n",
    "    axes[i].set_yticks([0, 0.2, 0.4, 0.6, 0.8])\n",
    "    axes[i].set_xlabel('observed', fontdict = {'size':20})\n",
    "    axes[i].set_ylabel('predicted', fontdict = {'size':20})\n",
    "    r = np.float16(stats.pearsonr(pred.flatten(), FG[FG.index.isin(Te_samps)])[0])\n",
    "    # p\n",
    "\n",
    "    axes[i].text(0.025, np.max(pred)-0.1,'n = %s/%s\\nr = %s'%(nT,nX,float('%.2g' % r)), fontsize=20)\n",
    "plt.savefig(os.path.join(fig_dir,'Cere_02_PLS_allsub_seperate.png'), \n",
    "            dpi=500, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Quick look at the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(pls_out['betas']))\n",
    "print(np.max(pls_out['betas']))\n",
    "# -0.0017709850960827796\n",
    "# 0.0014797712849072356"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(pls_out['betas'])[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig,axes= plt.subplots(1,3, figsize=(30,10))\n",
    "sns.set_context('poster',font_scale=1)\n",
    "sns.despine()\n",
    "\n",
    "sns.distplot(pls_out['betas'],kde=False, ax=axes[0], \n",
    "             hist_kws={ \"color\": jet_9[0], 'alpha': .7 })\n",
    "axes[0].set_xlim(-0.0020,-0.001)\n",
    "axes[0].set_xticks([-0.002,-0.0015,-0.001])\n",
    "axes[0].set_ylim(0,25)\n",
    "xval = sorted(pls_out['betas'])[50]\n",
    "plt.plot([xval, xval], [0, 100], linewidth=2)\n",
    "\n",
    "sns.distplot(pls_out['betas'],kde=False, ax=axes[1], \n",
    "             hist_kws={ \"color\": jet_9[0], 'alpha': .7 })\n",
    "axes[1].set_xlim(-0.0018,0.0016)\n",
    "axes[1].set_xticks([-0.0015,-0.00075,0,0.00075,0.0015])\n",
    "axes[1].set_xlabel('PLSR beta')\n",
    "axes[1].set_ylabel('N genes')\n",
    "\n",
    "\n",
    "sns.distplot(pls_out['betas'],kde=False, ax=axes[2], \n",
    "             hist_kws={ \"color\": jet_9[0], 'alpha': .7 })\n",
    "axes[2].set_xlim(0.001,0.0016)\n",
    "axes[2].set_xticks([0.0010,0.0012,0.0014,0.0016])\n",
    "axes[2].set_ylim(0,25)\n",
    "xval = sorted(pls_out['betas'])[-50]\n",
    "plt.plot([xval, xval], [0, 100], linewidth=2)\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(fig_dir,'Cere_02_PLS_Beta_Dist.png'),\n",
    "            dpi=500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "sns.set_context('poster',font_scale=0.8)\n",
    "\n",
    "# Major\n",
    "sns.distplot(pls_out['betas'],kde=False,\n",
    "             hist_kws={ \"color\": RdBu_200[185], 'alpha': .7 })\n",
    "sns.despine()\n",
    "plt.xlim(-0.0018,0.0016)\n",
    "plt.xticks([-0.0015,-0.00075,0,0.00075,0.0015], fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.xlabel('PLSR beta', fontsize=25)\n",
    "plt.ylabel('Number', fontsize=25)\n",
    "\n",
    "# left\n",
    "al = plt.axes([.18, .2, 0.15, 0.4])\n",
    "sns.distplot(pls_out['betas'],kde=False, \n",
    "             hist_kws={ \"color\": RdBu_200[185], 'alpha': .7 })\n",
    "plt.xlim(-0.0020,-0.001)\n",
    "plt.xticks([-0.002,-0.0015,-0.001], fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.ylim(0,25)\n",
    "xval = sorted(pls_out['betas'])[50]\n",
    "plt.plot([xval, xval], [0, 100], linewidth=4, color=RdBu_200[185])\n",
    "\n",
    "# right\n",
    "ar = plt.axes([.7, .2, 0.15, 0.4])\n",
    "sns.distplot(pls_out['betas'],kde=False, \n",
    "             hist_kws={ \"color\": RdBu_200[185], 'alpha': .7 })\n",
    "plt.xlim(0.0009,0.0016)\n",
    "plt.xticks([0.0010,0.0013,0.0016], fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.ylim(0,25)\n",
    "xval = sorted(pls_out['betas'])[-50]\n",
    "plt.plot([xval, xval], [0, 100], linewidth=4, color=RdBu_200[185])\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(fig_dir,'Cere_02_PLS_Beta_Dist.png'),\n",
    "            dpi=700/24*15, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression.columns[pandas.Series(pls_out['betas'][:,0]).sort_values(ascending=False)[:50].index].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression.columns[pandas.Series(pls_out['betas'][:,0]).sort_values(ascending=True)[:50].index].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE TABLE FOR OVERLEAF\n",
    "df = pandas.DataFrame(pls_out['betas'])\n",
    "df.index = expression.columns\n",
    "df.columns = ['beta']\n",
    "gene_table = df.sort_values(ascending=False, by = 'beta')\n",
    "gene_table.to_csv(os.path.join(data_dir,'PLS_Betas_cere2extra_15624.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Test the signifcance of each beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "brainsmash to refit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheetlist = f'{data_dir}/Permutation/cere_317samples_genelevel/PLS_Beta_BrainSmash_Value_Y_17853_*000.csv'\n",
    "xpsheets = sorted(glob(sheetlist))\n",
    "\n",
    "Beta_perm = pandas.DataFrame()\n",
    "for sheet in tqdm(xpsheets):\n",
    "    # fid = int(sheet.split('/')[-1].split('_')[-2])\n",
    "    Beta_cur= pandas.read_csv(sheet, index_col=0)\n",
    "    Beta_perm = pandas.concat([Beta_cur, Beta_perm], axis=1)\n",
    "Beta_perm.index = expression.columns\n",
    "Beta_perm.columns = range(len(Beta_perm.T))\n",
    "\n",
    "gene_table['p_perm'] = [abs(Beta_perm.loc[x,:]).ge(abs(gene_table.loc[x,'beta'])).sum()/len(Beta_perm.T) for x in gene_table.index]\n",
    "# 1/10001 > (0.05/15624), so we just use the value larger than the tru divided by the permutation times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_table['p_perm_fdr0.05'] = gene_table['p_perm']<(0.05/15624)\n",
    "len(gene_table[gene_table['p_perm_fdr0.05']==True]) # 1024 genes\n",
    "gene_table['type'] = ''\n",
    "for x in gene_table.index: \n",
    "    if gene_table.loc[x,'beta'] > 0:\n",
    "        gene_table.loc[x,'type'] = 'pos'\n",
    "        if (~gene_table.loc[x,'p_perm_fdr0.05']):\n",
    "            gene_table.loc[x,'type'] = 'nosig'\n",
    "    if gene_table.loc[x,'beta'] < 0:\n",
    "        gene_table.loc[x,'type'] = 'neg'\n",
    "        if (~gene_table.loc[x,'p_perm_fdr0.05']):\n",
    "            gene_table.loc[x,'type'] = 'nosig'\n",
    "gene_table['color'] = ''\n",
    "for x in gene_table.index: \n",
    "    if gene_table.loc[x,'beta'] > 0:\n",
    "        gene_table.loc[x,'color'] = Hex_2[1]\n",
    "        if (~gene_table.loc[x,'p_perm_fdr0.05']):\n",
    "            gene_table.loc[x,'color'] = \"grey\"\n",
    "    if gene_table.loc[x,'beta'] < 0:\n",
    "        gene_table.loc[x,'color'] = Hex_1[2]\n",
    "        if (~gene_table.loc[x,'p_perm_fdr0.05']):\n",
    "            gene_table.loc[x,'color'] = \"grey\"\n",
    "gene_table.to_csv(os.path.join(data_dir,'PLS_Betas_cere2extra_15624_permutation.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_table=pd.read_csv(f'{data_dir}/PLS_Betas_cere2extra_15624_permutation.csv', index_col=0)\n",
    "gene_table_sig = gene_table.loc[gene_table.loc[:,'p_perm_fdr0.05'],:] # 0.05 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "sns.set_context('poster',font_scale=0.8)\n",
    "sns.distplot(gene_table_sig['beta'], 25, hist=True, kde=False,\n",
    "             hist_kws={ \"color\": RdBu_200[25], 'alpha': .7, \"edgecolor\": \"white\" })\n",
    "sns.despine()\n",
    "# plt.xlim(-0.0018,0.015)\n",
    "plt.xticks([-.002,-.001,0,.001, .002], fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.xlabel('PLSR beta', fontsize=25)\n",
    "plt.ylabel('Number', fontsize=25)\n",
    "plt.savefig(os.path.join(fig_dir,'Cere_02_PLS_Beta_Dist_sig.png'),\n",
    "            dpi=700/24*7.5, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig = plt.figure(figsize=(24,10))\n",
    "\n",
    "plt.subplot(121)\n",
    "sns.set_context('poster',font_scale=1)\n",
    "\n",
    "# Major\n",
    "sns.distplot(pls_out['betas'],kde=False,\n",
    "             hist_kws={ \"color\": RdBu_200[185], 'alpha': .7 })\n",
    "sns.despine()\n",
    "plt.xlim(-0.0018,0.0016)\n",
    "plt.xticks([-0.0015,-0.00075,0,0.00075,0.0015], fontsize=20)\n",
    "plt.xlabel('PLSR beta', fontsize=25)\n",
    "plt.ylabel('N genes', fontsize=25)\n",
    "\n",
    "# left\n",
    "al = plt.axes([.18, .2, 0.15, 0.4])\n",
    "sns.distplot(pls_out['betas'],kde=False, \n",
    "             hist_kws={ \"color\": RdBu_200[185], 'alpha': .7 })\n",
    "plt.xlim(-0.0020,-0.001)\n",
    "plt.xticks([-0.002,-0.0015,-0.001])\n",
    "plt.ylim(0,25)\n",
    "xval = sorted(pls_out['betas'])[50]\n",
    "plt.plot([xval, xval], [0, 100], linewidth=4, color=jet_9[0])\n",
    "\n",
    "# right\n",
    "ar = plt.axes([.7, .2, 0.15, 0.4])\n",
    "sns.distplot(pls_out['betas'],kde=False, \n",
    "             hist_kws={ \"color\": RdBu_200[185], 'alpha': .7 })\n",
    "plt.xlim(0.0009,0.0016)\n",
    "plt.xticks([0.0010,0.0013,0.0016])\n",
    "plt.ylim(0,25)\n",
    "xval = sorted(pls_out['betas'])[-50]\n",
    "plt.plot([xval, xval], [0, 100], linewidth=4, color=jet_9[0])\n",
    "\n",
    "\n",
    "plt.subplot(122)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "5fc7b758da90ada7c8031b2f484e4e7cb897fdecc503f72250cf9ae1f1151ca2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
